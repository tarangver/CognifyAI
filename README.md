# ğŸ§  CognifyAI - GenAI Research Summarization Assistant

CognifyAI is a GenAI-powered assistant that reads structured documents (PDF/TXT), generates intelligent summaries, allows users to ask contextual questions, and evaluates comprehension through logic-based Q&A.

## ğŸ”— Live App: **Launch [CognifyAI](https://cognifyai-ez.streamlit.app/)**

## ğŸš€ Features

- ğŸ“„ **Upload Document** (PDF/TXT)
- ğŸ§  **Auto-Summarization** (â‰¤150 words)
- ğŸ’¬ **Ask Anything**: Free-form Q&A based on document context
- ğŸ§ª **Challenge Me**: Generates 3 logic-based questions and evaluates your answers
- âœ… **Justified Answers**: All responses cite back to original content
- ğŸ” **Semantic Chunk Matching** using sentence transformers
- ğŸ” **Groq API** integration with `llama-3.1-8b-instant` model

---

## ğŸ§° Tech Stack

| Layer         | Technology                      |
|---------------|----------------------------------|
| UI            | Streamlit                        |
| Backend       | Python                           |
| LLM           | Groq API (llama-3.1-8b-instant)           |
| Embeddings    | sentence-transformers (MiniLM)   |
| PDF Parsing   | PyMuPDF                          |
| Environment   | python-dotenv, virtualenv        |

---

## ğŸ“ Folder Structure

```
CognifyAI/
â”œâ”€â”€ app.py                     # Streamlit main app
â”œâ”€â”€ .env                       # API keys
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ parser.py              # PDF/TXT parsing
â”‚   â”œâ”€â”€ summarizer.py          # Summarization logic
â”‚   â”œâ”€â”€ qa_engine.py           # Ask Anything logic
â”‚   â”œâ”€â”€ challenge_gen.py       # Challenge Me logic
â”‚   â”œâ”€â”€ evaluator.py           # Answer evaluation logic
â”‚   â”œâ”€â”€ chunker.py             # Document chunking
â”‚   â””â”€â”€ utils.py               # API calls, similarity, helper functions
â”‚
â””â”€â”€ constants/
    â””â”€â”€ prompts.py             # Prompt templates
```

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/tarangver/CognifyAI.git
cd CognifyAI
```

### 2. Install Required Packages

```bash
pip install -r requirements.txt
```

### 3. Add your `.env` file

Create a file if not already created named `.env` in the root folder with this content:

```env
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
```

> âœ… You can replace `llama-3.1-8b-instant` with other Groq-supported models like `llama3-70b-8192` or `gemma-7b-it`.

---

## â–¶ï¸ Running the App

```bash
streamlit run app.py
```

It will open in your browser at:
[http://localhost:8501](http://localhost:8501)

---

## ğŸ§ª How to Use

1. Upload a PDF or TXT file via the sidebar.
2. View a concise summary (â‰¤150 words).
3. Choose:
   - **Ask Anything** â€“ Type questions based on the document
   - **Challenge Me** â€“ Let the AI generate 3 questions and test your comprehension
4. Receive AI answers + source-based justifications

---

## âš™ï¸ Available Models (Groq)

You may use any of the following Groq models:

- `gemma-7b-it`
- `llama3-70b-8192`
- `llama-3.1-8b-instant`

Make sure your key supports the one you're using.

---

## ğŸ§  How It Works

- Text is extracted from PDF/TXT â†’ chunked manually
- For QA, chunks are ranked using semantic similarity (MiniLM embeddings)
- Groq API is used for:
  - Auto-summary
  - Answering user questions
  - Generating logical questions
  - Evaluating user answers with justification

---

## ğŸ“Œ TODO... Improvements

- [ ] Answer snippet highlighting
- [ ] File download (summary, quiz result)
- [ ] Conversation memory (contextual follow-ups)
- [ ] Switchable models via dropdown
- [ ] Add citations by paragraph number

---

## ğŸ‘¨â€ğŸ’» Author



Made with â¤ï¸ by **TARANG VERMA** as part of the **EZ GenAI Internship Task**.

---

## ğŸ›¡ï¸ License

This project is open source and available under the [MIT License](LICENSE).
